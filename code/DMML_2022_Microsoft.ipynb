{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZKqCFFbNZ04"
      },
      "source": [
        "# Data Mining and Machine Learning - Project\n",
        "\n",
        "## Detecting Difficulty Level of French Texts\n",
        "\n",
        "### Step by step guidelines\n",
        "\n",
        "The following are a set of step by step guidelines to help you get started with your project for the Data Mining and Machine Learning class. \n",
        "To test what you learned in the class, we will hold a competition. You will create a classifier that predicts how the level of some text in French (A1,..., C2). The team with the highest rank will get some goodies in the last class (some souvenirs from tech companies: Amazon, LinkedIn, etc).\n",
        "\n",
        "**2 people per team**\n",
        "\n",
        "Choose a team here:\n",
        "https://moodle.unil.ch/mod/choicegroup/view.php?id=1305831\n",
        "\n",
        "\n",
        "#### 1. üìÇ Create a public GitHub repository for your team using this naming convention `DMML2022_[your_team_name]` with the following structure:\n",
        "- data (folder) \n",
        "- code (folder) \n",
        "- documentation (folder)\n",
        "- a readme file (.md): *mention team name, participants, brief description of the project, approach, summary of results table and link to the explainatory video (see below).*\n",
        "\n",
        "All team members should contribute to the GitHub repository.\n",
        "\n",
        "#### 2. üá∞ Join the competititon on Kaggle using the invitation link we sent on Slack.\n",
        "\n",
        "Under the Team tab, save your team name (`UNIL_your_team_name`) and make sure your team members join in as well. You can merge your user account with your teammates in order to create a team.\n",
        "\n",
        "#### 3. üìì Read the data into your colab notebook. There should be one code notebook per team, but all team members can participate and contribute code. \n",
        "\n",
        "You can use either direct the Kaggle API and your Kaggle credentials (as explained below and **entirely optional**), or dowload the data form Kaggle and upload it onto your team's GitHub repository under the data subfolder.\n",
        "\n",
        "#### 4. üíé Train your models and upload the code under your team's GitHub repo. Set the `random_state=0`.\n",
        "- baseline\n",
        "- logistic regression with TFidf vectoriser (simple, no data cleaning)\n",
        "- KNN & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Decision Tree classifier & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Random Forests classifier (simple, no data cleaning)\n",
        "- another technique or combination of techniques of your choice\n",
        "\n",
        "BE CREATIVE! You can use whatever method you want, in order to climb the leaderboard. The only rule is that it must be your own work. Given that, you can use all the online resources you want. \n",
        "\n",
        "#### 5. üé• Create a YouTube video (5-10 minutes) of your solution and embed it in your notebook. Explain the algorithms used and the evaluation of your solutions. *Select* projects will also be presented live by the group during the last class.\n",
        "\n",
        "\n",
        "### Submission details (one per team)\n",
        "\n",
        "1. Download a ZIPped file of your team's repository and submit it in Moodle here. IMPORTANT: in the comment of the submission, insert a link to the repository on Github.\n",
        "https://moodle.unil.ch/mod/assign/view.php?id=1305833\n",
        "\n",
        "\n",
        "\n",
        "### Grading (one per team)\n",
        "- 20% Kaggle Rank\n",
        "- 50% code quality (using classes, splitting into proper files, documentation, etc)\n",
        "- 15% github quality (include link to video, table with progress over time, organization of code, images, etc)\n",
        "- 15% video quality (good sound, good slides, interesting presentation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-14CAdOoinM"
      },
      "source": [
        "## Some further details for points 3 and 4 above.\n",
        "\n",
        "### 3. Read data into your notebook with the Kaggle API (optional but useful). \n",
        "\n",
        "You can also download the data from Kaggle and put it in your team's repo the data folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ_hnJzSNO2g",
        "outputId": "5420def3-f26d-442a-bdf7-e28f277f92fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# reading in the data via the Kaggle API\n",
        "\n",
        "# mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyWvCPdEdJik",
        "outputId": "bdbd4b99-2100-4955-92f8-600c575da31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fr-core-news-lg==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.4.0/fr_core_news_lg-3.4.0-py3-none-any.whl (571.8 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 571.8 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from fr-core-news-lg==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (21.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->fr-core-news-lg==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_lg')\n"
          ]
        }
      ],
      "source": [
        "# Install and update spaCy\n",
        "!pip install -U spacy\n",
        "\n",
        "# Download the large french language model\n",
        "!python -m spacy download fr_core_news_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB2R58PqdM4R",
        "outputId": "409295c5-0938-4570-983d-144bb063dc4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.8/dist-packages (1.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "# install \n",
        "! pip install kaggle transformers sentencepiece Keras-Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKG1TCddRYTB"
      },
      "source": [
        "### IMPORTANT\n",
        "Log into your Kaggle account, go to Account > API > Create new API token. You will obtain a kaggle.json file. Save it in your Google Drive (not in a folder, in your general drive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JgzLj451YDfV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73e8313-e6e8-4fa3-c978-a0516d9c19e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‚Äò/root/.kaggle‚Äô: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KrsZLalrSI3u"
      },
      "outputs": [],
      "source": [
        "#read in your Kaggle credentials from Google Drive\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-mn-aQ84caOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5998ea2c-306d-434f-b897-ff62e24ea48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‚Äòdata‚Äô: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDI60LXKTPzf",
        "outputId": "b5a05a92-f5d5-4174-d783-b724ff3654ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detecting-french-texts-difficulty-level-2022.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "# download the dataset from the competition page\n",
        "! kaggle competitions download -c detecting-french-texts-difficulty-level-2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T59Ef9UIcaO0",
        "outputId": "aa2e0e5c-d077-4caa-dca2-2844513fb43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  detecting-french-texts-difficulty-level-2022.zip\n",
            "replace data/sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/sample_submission.csv  \n",
            "  inflating: data/training_data.csv  \n",
            "  inflating: data/unlabelled_test_data.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"detecting-french-texts-difficulty-level-2022.zip\" -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "o2ag36SIcqJM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import string\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertTokenizer, CamembertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from collections import Counter\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "daqvj7feTx60"
      },
      "outputs": [],
      "source": [
        "# read in data\n",
        "df = pd.read_csv('/content/data/training_data.csv')\n",
        "df_pred = pd.read_csv('/content/data/unlabelled_test_data.csv')\n",
        "df_example_submission = pd.read_csv('/content/data/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpfbtndj0jL"
      },
      "source": [
        "Have a look at the data on which to make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a37hWJ_ckBlk"
      },
      "source": [
        "And this is the format for your submissions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfTgL1erjqQ6"
      },
      "source": [
        "### 4. Train your models\n",
        "\n",
        "Set your X and y variables. \n",
        "Set the `random_state=0`\n",
        "Split the data into a train and test set using the following parameters `train_test_split(X, y, test_size=0.2, random_state=0)`.\n",
        "\n",
        "#### 4.1.Baseline\n",
        "What is the baseline for this classification problem?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4O_pYiHpiRd"
      },
      "outputs": [],
      "source": [
        "np.random.seed = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDdFr4xsk5Qf",
        "outputId": "9e9b77d3-3a73-4a0b-8f6c-ebf70e0199eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base rate:\n",
            "0.1694\n"
          ]
        }
      ],
      "source": [
        "base_rate = np.max(df.difficulty.value_counts()/df.difficulty.shape[0]) \n",
        "\n",
        "print(f\"Base rate:\\n{base_rate:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlvbPYa0k78l"
      },
      "source": [
        "#### 4.2. Logistic Regression (without data cleaning)\n",
        "\n",
        "Train a simple logistic regression model using a Tfidf vectoriser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "eEe3-QNlow4H"
      },
      "outputs": [],
      "source": [
        "X = df['sentence'] \n",
        "y = df['difficulty'] \n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "djlYIZcydSMJ"
      },
      "outputs": [],
      "source": [
        "# Define vectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Define classifier\n",
        "classifier = LogisticRegression() #different solver? number iterations?\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ-qO8C5oyov"
      },
      "source": [
        "Calculate accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "PViIQdnDpASy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6970aa-7686-4c63-fb62-00d8d0f1c6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[93 31 21 10  4  2]\n",
            " [54 60 30  6  6  8]\n",
            " [12 38 64 17  9 20]\n",
            " [ 6  6 15 66 27 24]\n",
            " [ 4  4 10 37 73 45]\n",
            " [ 7  8  8 19 24 92]]\n",
            "ACCURACY SCORE:\n",
            "0.4667\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4656\n",
            "\tRecall: 0.4667\n",
            "\tF1_Score: 0.4640\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the model\n",
        "def evaluate(true, pred):\n",
        "    precision = precision_score(true, pred, average='weighted') #other average options: None, 'micro', 'macro'\n",
        "    recall = recall_score(true, pred, average='weighted')\n",
        "    f1 = f1_score(true, pred, average='weighted')\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    accuracy = accuracy_score(true, pred)\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")\n",
        "    return precision, recall, f1, accuracy\n",
        "\n",
        "# Evaluate and save results for table\n",
        "log_reg_results = evaluate(y_test, y_pred)\n",
        "log_reg_percision = log_reg_results[0]\n",
        "log_reg_recall = log_reg_results[1]\n",
        "log_reg_f1 = log_reg_results[2]\n",
        "log_reg_accuracy = log_reg_results[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "MOCUAImEebw7"
      },
      "outputs": [],
      "source": [
        "#Test out different tfidf configurations:\n",
        "\n",
        "# Create list of configs\n",
        "def configs():\n",
        "\n",
        "    models = list()\n",
        "    \n",
        "    # Define config lists\n",
        "    ngram_range = [(1,1), (1,2), (1,3), (2,2), (2,3), (3,3)]\n",
        "    min_df = [1]\n",
        "    max_df = [1.0]\n",
        "    analyzer=['word', 'char']\n",
        "    \n",
        "    # Create config instances\n",
        "    for n in ngram_range:\n",
        "        for i in min_df:\n",
        "            for j in max_df:\n",
        "              for a in analyzer:\n",
        "                    cfg = [n, i, j, a]\n",
        "                    models.append(cfg)\n",
        "    return models\n",
        "\n",
        "configs = configs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvR5Y3NJebTG",
        "outputId": "5ef63a73-f318-47b4-ae96-62d31a173785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONFIG:  [(1, 1), 1, 1.0, 'word']\n",
            "CONFUSION MATRIX:\n",
            "[[93 31 21 10  4  2]\n",
            " [54 60 30  6  6  8]\n",
            " [12 38 64 17  9 20]\n",
            " [ 6  6 15 66 27 24]\n",
            " [ 4  4 10 37 73 45]\n",
            " [ 7  8  8 19 24 92]]\n",
            "ACCURACY SCORE:\n",
            "0.4667\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4656\n",
            "\tRecall: 0.4667\n",
            "\tF1_Score: 0.4640\n",
            "-----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONFIG:  [(1, 1), 1, 1.0, 'char']\n",
            "CONFUSION MATRIX:\n",
            "[[84 31 17 15  5  9]\n",
            " [42 60 35 10  6 11]\n",
            " [16 35 62 18 12 17]\n",
            " [ 6  6 11 42 42 37]\n",
            " [ 5  3 13 45 43 64]\n",
            " [ 5  4  8 27 34 80]]\n",
            "ACCURACY SCORE:\n",
            "0.3865\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3888\n",
            "\tRecall: 0.3865\n",
            "\tF1_Score: 0.3846\n",
            "-----------------------\n",
            "CONFIG:  [(1, 2), 1, 1.0, 'word']\n",
            "CONFUSION MATRIX:\n",
            "[[ 87  32  23   9   3   7]\n",
            " [ 50  60  33   4   7  10]\n",
            " [ 17  36  63  11  11  22]\n",
            " [  6   3  13  56  25  41]\n",
            " [  2   4  13  19  67  68]\n",
            " [  6   5   8  12  19 108]]\n",
            "ACCURACY SCORE:\n",
            "0.4594\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4653\n",
            "\tRecall: 0.4594\n",
            "\tF1_Score: 0.4541\n",
            "-----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONFIG:  [(1, 2), 1, 1.0, 'char']\n",
            "CONFUSION MATRIX:\n",
            "[[104  26  19   5   4   3]\n",
            " [ 49  68  32   7   1   7]\n",
            " [ 14  26  75  25   9  11]\n",
            " [  5   6   8  60  26  39]\n",
            " [  6   1  11  43  59  53]\n",
            " [  6   9   3  25  30  85]]\n",
            "ACCURACY SCORE:\n",
            "0.4698\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4723\n",
            "\tRecall: 0.4698\n",
            "\tF1_Score: 0.4670\n",
            "-----------------------\n",
            "CONFIG:  [(1, 3), 1, 1.0, 'word']\n",
            "CONFUSION MATRIX:\n",
            "[[ 84  33  23   8   3  10]\n",
            " [ 52  57  31   3   7  14]\n",
            " [ 18  31  58  11  10  32]\n",
            " [  4   3  10  47  20  60]\n",
            " [  2   3  13  16  59  80]\n",
            " [  5   6   6  11  17 113]]\n",
            "ACCURACY SCORE:\n",
            "0.4354\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4524\n",
            "\tRecall: 0.4354\n",
            "\tF1_Score: 0.4282\n",
            "-----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONFIG:  [(1, 3), 1, 1.0, 'char']\n",
            "CONFUSION MATRIX:\n",
            "[[107  28  17   5   4   0]\n",
            " [ 50  69  37   6   1   1]\n",
            " [ 18  35  73  21   8   5]\n",
            " [  4   8   6  62  30  34]\n",
            " [  6   3   9  43  67  45]\n",
            " [  6   7   1  29  27  88]]\n",
            "ACCURACY SCORE:\n",
            "0.4854\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4855\n",
            "\tRecall: 0.4854\n",
            "\tF1_Score: 0.4828\n",
            "-----------------------\n",
            "CONFIG:  [(2, 2), 1, 1.0, 'word']\n",
            "CONFUSION MATRIX:\n",
            "[[75 38 24 17  4  3]\n",
            " [45 56 31 10 11 11]\n",
            " [25 31 57 19  9 19]\n",
            " [ 9 10 19 52 20 34]\n",
            " [ 4  4 15 40 59 51]\n",
            " [ 5  8 12 32 24 77]]\n",
            "ACCURACY SCORE:\n",
            "0.3917\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3970\n",
            "\tRecall: 0.3917\n",
            "\tF1_Score: 0.3913\n",
            "-----------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONFIG:  [(2, 2), 1, 1.0, 'char']\n",
            "CONFUSION MATRIX:\n",
            "[[105  29  15   5   6   1]\n",
            " [ 50  66  32   8   2   6]\n",
            " [ 18  24  77  23   9   9]\n",
            " [  4   8  10  61  28  33]\n",
            " [  8   3  11  40  63  48]\n",
            " [  6  10   4  25  32  81]]\n",
            "ACCURACY SCORE:\n",
            "0.4719\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4713\n",
            "\tRecall: 0.4719\n",
            "\tF1_Score: 0.4690\n",
            "-----------------------\n",
            "CONFIG:  [(2, 3), 1, 1.0, 'word']\n",
            "CONFUSION MATRIX:\n",
            "[[75 35 24 17  4  6]\n",
            " [46 55 31 11 11 10]\n",
            " [25 27 58 18 11 21]\n",
            " [ 9  8 20 51 18 38]\n",
            " [ 4  4 18 42 56 49]\n",
            " [ 5  9 10 29 24 81]]\n",
            "ACCURACY SCORE:\n",
            "0.3917\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3968\n",
            "\tRecall: 0.3917\n",
            "\tF1_Score: 0.3903\n",
            "-----------------------\n",
            "CONFIG:  [(2, 3), 1, 1.0, 'char']\n",
            "CONFUSION MATRIX:\n",
            "[[110  28  16   4   3   0]\n",
            " [ 54  69  33   6   1   1]\n",
            " [ 19  30  75  24   8   4]\n",
            " [  5   8   8  62  32  29]\n",
            " [  8   4   6  45  64  46]\n",
            " [  6   8   2  30  26  86]]\n",
            "ACCURACY SCORE:\n",
            "0.4854\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4865\n",
            "\tRecall: 0.4854\n",
            "\tF1_Score: 0.4823\n",
            "-----------------------\n",
            "CONFIG:  [(3, 3), 1, 1.0, 'word']\n",
            "CONFUSION MATRIX:\n",
            "[[45 14 13 84  3  2]\n",
            " [26 36 19 77  4  2]\n",
            " [19 21 36 69  8  7]\n",
            " [ 5  9  7 98  7 18]\n",
            " [ 2  8 15 97 28 23]\n",
            " [ 1  7  4 88 19 39]]\n",
            "ACCURACY SCORE:\n",
            "0.2938\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3779\n",
            "\tRecall: 0.2938\n",
            "\tF1_Score: 0.2910\n",
            "-----------------------\n",
            "CONFIG:  [(3, 3), 1, 1.0, 'char']\n",
            "CONFUSION MATRIX:\n",
            "[[105  29  17   6   4   0]\n",
            " [ 55  67  30   7   2   3]\n",
            " [ 20  34  72  21   8   5]\n",
            " [  4   9   8  67  29  27]\n",
            " [  5   7   8  41  71  41]\n",
            " [  8   7   2  26  31  84]]\n",
            "ACCURACY SCORE:\n",
            "0.4854\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4863\n",
            "\tRecall: 0.4854\n",
            "\tF1_Score: 0.4832\n",
            "-----------------------\n"
          ]
        }
      ],
      "source": [
        "# Define list for result\n",
        "result = []\n",
        "\n",
        "for config in configs:\n",
        "\n",
        "    # Redefine vectorizer\n",
        "    tfidf_vector = TfidfVectorizer(ngram_range=config[0],\n",
        "                                   min_df=config[1], max_df=config[2], analyzer=config[3])\n",
        "\n",
        "    # Define classifier\n",
        "    classifier = LogisticRegression() #(solver='lbfgs', cv=5, max_iter=1000)\n",
        "\n",
        "    # Create pipeline\n",
        "    pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "    # Fit model on training set\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    # Print accuracy on test set\n",
        "    print(\"CONFIG: \", config)\n",
        "    evaluate(y_test, y_pred)\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    # Append to result\n",
        "    result.append([config, accuracy_score(y_test, y_pred)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D3_dp3apcmr"
      },
      "source": [
        "Have a look at the confusion matrix and identify a few examples of sentences that are not well classified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ8eIjXTVj6A",
        "outputId": "fd1b8052-9314-4630-d85e-08a01e1e6a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[110  28  16   4   3   0]\n",
            " [ 54  69  33   6   1   1]\n",
            " [ 19  30  75  24   8   4]\n",
            " [  5   8   8  62  32  29]\n",
            " [  8   4   6  45  64  46]\n",
            " [  6   8   2  30  26  86]]\n",
            "ACCURACY SCORE:\n",
            "0.4854\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4865\n",
            "\tRecall: 0.4854\n",
            "\tF1_Score: 0.4823\n"
          ]
        }
      ],
      "source": [
        "#re-evaluate:\n",
        "\n",
        "# Define vectorizer\n",
        "tfidf = TfidfVectorizer(ngram_range=(2,3), min_df = 1, max_df = 1.0, analyzer='char')\n",
        "\n",
        "# Define classifier\n",
        "classifier = LogisticRegression() #different solver? number iterations?\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluate and save results for table\n",
        "log_reg_results = evaluate(y_test, y_pred)\n",
        "log_reg_percision = log_reg_results[0]\n",
        "log_reg_recall = log_reg_results[1]\n",
        "log_reg_f1 = log_reg_results[2]\n",
        "log_reg_accuracy = log_reg_results[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSyKq3h_qZmX",
        "outputId": "ef09aa74-1ac4-4207-af48-22c693d28f50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2255    C'est en d√©cembre 1967, apr√®s bien des invecti...\n",
              "608     Giscard va pourtant r√©ussir √† transformer ce r...\n",
              "2856    Un choix difficile mais important : le public ...\n",
              "1889    Le d√©bat porte plut√¥t sur l'utilit√© d'une tell...\n",
              "2250    Vous eussiez jur√© que les gens la voyaient, l'...\n",
              "                              ...                        \n",
              "1450    Le slogan \"100 % de nos clients ach√®tent nos p...\n",
              "3944    En √©t√©, j'aime faire de la randonn√©e et vous, ...\n",
              "891     Tr√®s pr√©sente dans l'alimentation antillaise, ...\n",
              "1005    On r√©invente le dimanche dans une perspective ...\n",
              "1940    Pour les femmes surtout, nuancent R√©gine Lemoi...\n",
              "Name: sentence, Length: 494, dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "misclassified_samples = X_test[y_test != y_pred]\n",
        "misclassified_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TTEiuXasNFg"
      },
      "source": [
        "Generate your first predictions on the `unlabelled_test_data.csv`. make sure your predictions match the format of the `unlabelled_test_data.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGIE7WpMetmC",
        "outputId": "9456c217-f8c3-48e3-9410-5fc142e754d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       Nous d√ªmes nous excuser des propos que nous e√ª...\n",
              "1       Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2       Et, paradoxalement, boire froid n'est pas la b...\n",
              "3       Ce n'est pas √©tonnant, car c'est une saison my...\n",
              "4       Le corps de Golo lui-m√™me, d'une essence aussi...\n",
              "                              ...                        \n",
              "1195    C'est un ph√©nom√®ne qui trouve une acc√©l√©ration...\n",
              "1196    Je vais parler au serveur et voir si on peut d...\n",
              "1197    Il n'√©tait pas comme tant de gens qui par pare...\n",
              "1198        Ils deviennent dangereux pour notre √©conomie.\n",
              "1199    Son succ√®s a g√©n√©r√© beaucoup de r√©actions n√©ga...\n",
              "Name: sentence, Length: 1200, dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unseen_test = df_pred['sentence']\n",
        "unseen_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "lpm9vCM0euTW",
        "outputId": "22e26aa6-d05a-47bc-a9ff-afd4caca4caa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0a98c8de-ffb8-4203-b42c-8352ea2ef0e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1195</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1196</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1197</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1198</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1199</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a98c8de-ffb8-4203-b42c-8352ea2ef0e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a98c8de-ffb8-4203-b42c-8352ea2ef0e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a98c8de-ffb8-4203-b42c-8352ea2ef0e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id difficulty\n",
              "0        0         C2\n",
              "1        1         B1\n",
              "2        2         A1\n",
              "3        3         B1\n",
              "4        4         C2\n",
              "...    ...        ...\n",
              "1195  1195         B1\n",
              "1196  1196         A2\n",
              "1197  1197         C2\n",
              "1198  1198         A2\n",
              "1199  1199         B2\n",
              "\n",
              "[1200 rows x 2 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unseen_test_data_pred = pipe.predict(unseen_test)\n",
        "df_pred['difficulty'] = unseen_test_data_pred\n",
        "df_pred_results = df_pred[[ \"id\",\"difficulty\"]]\n",
        "df_pred_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXG_yIG_pQ8t"
      },
      "source": [
        "#### 4.3. KNN (without data cleaning)\n",
        "\n",
        "Train a KNN classification model using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPRjD1rSqKKZ",
        "outputId": "6f5084c4-9437-48c9-8cd3-11ac4e92c45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[110  34   8   0   1   8]\n",
            " [ 65  55  12   6   3  23]\n",
            " [ 32  34  25   7   8  54]\n",
            " [  7   7   3  26  12  89]\n",
            " [  6   2   6   8  21 130]\n",
            " [  8   4   3   7  10 126]]\n",
            "ACCURACY SCORE:\n",
            "0.3781\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4124\n",
            "\tRecall: 0.3781\n",
            "\tF1_Score: 0.3390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4123541248033652, 0.378125, 0.3390151728554922, 0.378125)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# Define classifier\n",
        "classifier = KNeighborsClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6rH2Hx0qtB2"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`n_neighbors`,   `p`, `weights`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRy18Ce_qxPc",
        "outputId": "692d7bbc-3bb8-4d73-9458-568449a4c64b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}\n"
          ]
        }
      ],
      "source": [
        "# Grid Search - hyperparameter tuning\n",
        "\n",
        "# Define parameters to test\n",
        "grid = {'n_neighbors':np.arange(1,100),\n",
        "        'p':np.arange(1,3),\n",
        "        'weights':['uniform','distance']\n",
        "       }\n",
        "\n",
        "# Define and fit model\n",
        "knn = KNeighborsClassifier()\n",
        "knn_cv = GridSearchCV(knn, grid, cv=10)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', knn_cv)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Print results\n",
        "print(\"Hyperparameters:\", knn_cv.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9xnI2EpfFvO",
        "outputId": "4cb1e826-8c0d-41c6-d536-7a04ee2322ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[123  25  10   1   0   2]\n",
            " [ 75  57  15   6   3   8]\n",
            " [ 51  38  29   8  10  24]\n",
            " [ 11  20  16  39  13  45]\n",
            " [ 11   5   9  21  46  81]\n",
            " [ 13  15   4  15  22  89]]\n",
            "ACCURACY SCORE:\n",
            "0.3990\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4037\n",
            "\tRecall: 0.3990\n",
            "\tF1_Score: 0.3767\n"
          ]
        }
      ],
      "source": [
        "# Fit optimal KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=2, p=2, weights='uniform')\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', knn)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluate and save results for table\n",
        "knn_results = evaluate(y_test, y_pred)\n",
        "knn_percision = knn_results[0]\n",
        "knn_recall = knn_results[1]\n",
        "knn_f1 = knn_results[2]\n",
        "knn_accuracy = knn_results[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFNH1WgNqc62"
      },
      "source": [
        "#### 4.4. Decision Tree Classifier (without data cleaning)\n",
        "\n",
        "Train a Decison Tree classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4PByPdGq0FV",
        "outputId": "1c5c0e6a-4c74-4b2a-8619-b1d5a12ac7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[66 44 23 12  9  7]\n",
            " [38 40 38 23 11 14]\n",
            " [15 31 43 26 23 22]\n",
            " [12  8 25 30 40 29]\n",
            " [ 8 11 24 37 53 40]\n",
            " [ 9 11 19 26 41 52]]\n",
            "ACCURACY SCORE:\n",
            "0.2958\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.2989\n",
            "\tRecall: 0.2958\n",
            "\tF1_Score: 0.2970\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.29894838075229746,\n",
              " 0.29583333333333334,\n",
              " 0.2969798534299308,\n",
              " 0.29583333333333334)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Define classifier\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQHjvOp7q11L"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`max_depth`, the depth of the decision tree)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1Fzl5BUq8JN",
        "outputId": "fca76ba1-9783-4ecc-e7c4-787cb1697763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'max_depth': 6}\n"
          ]
        }
      ],
      "source": [
        "# Grid Search - tuning tree depth\n",
        "\n",
        "# Define parameter to test\n",
        "grid = {'max_depth':np.arange(1,7)}\n",
        "\n",
        "# Define and fit model\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree_cv = GridSearchCV(tree, grid, cv=5)\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', tree_cv)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Print results\n",
        "print(\"Hyperparameters:\", tree_cv.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrYf_WUNfM2P",
        "outputId": "2d4af13d-048c-4611-ae16-68fa95ac4337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[99 19 25 14  4  0]\n",
            " [59 39 29 25  6  6]\n",
            " [29 23 42 42 12 12]\n",
            " [ 9  6 20 52 40 17]\n",
            " [ 7  5 36 41 68 16]\n",
            " [ 9  3 25 41 54 26]]\n",
            "ACCURACY SCORE:\n",
            "0.3396\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3464\n",
            "\tRecall: 0.3396\n",
            "\tF1_Score: 0.3305\n"
          ]
        }
      ],
      "source": [
        "# Fit optimal tree model\n",
        "classifier = DecisionTreeClassifier(max_depth=6)\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluate and save results for table\n",
        "tree_results = evaluate(y_test, y_pred)\n",
        "tree_percision = tree_results[0]\n",
        "tree_recall = tree_results[1]\n",
        "tree_f1 = tree_results[2]\n",
        "tree_accuracy = tree_results[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M52Ys3hcq7ku"
      },
      "source": [
        "#### 4.5. Random Forest Classifier (without data cleaning)\n",
        "\n",
        "Try a Random Forest Classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sssF4NIGrNLa",
        "outputId": "9533e740-f6cf-4757-b1a4-76da7a8856a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[114  27  13   6   1   0]\n",
            " [ 63  61  25  10   2   3]\n",
            " [ 25  32  54  34   9   6]\n",
            " [  8   6  16  60  28  26]\n",
            " [  8   9  13  40  66  37]\n",
            " [  7  14   8  25  39  65]]\n",
            "ACCURACY SCORE:\n",
            "0.4375\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4362\n",
            "\tRecall: 0.4375\n",
            "\tF1_Score: 0.4317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4362195592957977, 0.4375, 0.43168945231089956, 0.4375)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Define classifier\n",
        "classifier = RandomForestClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHEFNsDYfXfa",
        "outputId": "af9c8e1b-1227-4bd5-c108-dfac3cc0e3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'max_depth': 6}\n"
          ]
        }
      ],
      "source": [
        "# Grid Search - tuning tree depth\n",
        "\n",
        "# Define parameter to test\n",
        "grid = {'max_depth':np.arange(1,7)}\n",
        "\n",
        "# Define and fit model\n",
        "\n",
        "tree = RandomForestClassifier()\n",
        "tree_cv = GridSearchCV(tree, grid, cv=5)\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', tree_cv)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Print results\n",
        "print(\"Hyperparameters:\", tree_cv.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrUvf9GOfZsV",
        "outputId": "b26d6839-aac1-47e9-8be8-d12ea09bb280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[130   9  17   1   3   1]\n",
            " [ 98  31  16  14   3   2]\n",
            " [ 38  29  37  34  12  10]\n",
            " [ 14   8   7  45  32  38]\n",
            " [ 16   6  10  26  53  62]\n",
            " [ 15   5   7  19  27  85]]\n",
            "ACCURACY SCORE:\n",
            "0.3969\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3886\n",
            "\tRecall: 0.3969\n",
            "\tF1_Score: 0.3723\n"
          ]
        }
      ],
      "source": [
        "# Fit optimal forest model\n",
        "classifier = RandomForestClassifier(max_depth=6, random_state=0)\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluate and save results for table\n",
        "forest_results = evaluate(y_test, y_pred)\n",
        "forest_percision = forest_results[0]\n",
        "forest_recall = forest_results[1]\n",
        "forest_f1 = forest_results[2]\n",
        "forest_accuracy = forest_results[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-8_3MK1rpZr"
      },
      "source": [
        "#### 4.6. Any other technique, including data cleaning if necessary\n",
        "\n",
        "Try to improve accuracy by training a better model using the techniques seen in class, or combinations of them.\n",
        "\n",
        "As usual, show the accuracy, precision, recall and f1 score on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model: Data Augmentation and Ensemble Classifier"
      ],
      "metadata": {
        "id": "ZHgtFxl-VieX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "wX5AjvvKr_nW"
      },
      "outputs": [],
      "source": [
        "#data augmentation:\n",
        "\n",
        "nlp = spacy.load('fr_core_news_lg')\n",
        "punctuations = string.punctuation\n",
        "stop_words = spacy.lang.fr.stop_words.STOP_WORDS\n",
        "\n",
        "# Entity Recognition\n",
        "def add_entity(sentence):\n",
        "    # Tokenize the sentence\n",
        "    doc = nlp(sentence)\n",
        "    # Return text and label for each sentence\n",
        "    return [(i.text, i.label_) for i in doc.ents]\n",
        "\n",
        "# Part of speech\n",
        "def add_POS(sentence):\n",
        "    # Tokenize the sentence\n",
        "    doc = nlp(sentence)\n",
        "    # Return tag of each token\n",
        "    return [(i, i.pos_) for i in doc]\n",
        "\n",
        "def entity_count(sentence: string):\n",
        "    # count entity elements in each sentence\n",
        "    ner = add_entity(sentence)\n",
        "    count = Counter([i[1] for i in ner])\n",
        "    return count\n",
        "\n",
        "def POS_count(sentence: string):\n",
        "    # count pos elements in each sentence\n",
        "    pos = add_POS(sentence)\n",
        "    count = Counter([i[1] for i in pos])\n",
        "    return count\n",
        "\n",
        "def data_augmentation(dataframe: pd.DataFrame):\n",
        "    dataframe[\"num_words\"] = dataframe[\"sentence\"].apply(lambda x: len(x.split())) #add number of words per sentence\n",
        "    dataframe[\"avg_word_length\"] = dataframe['sentence'].apply(lambda x: np.sum([len(w) for w in x.split()]) / len(x.split())) #add average word length\n",
        "    dataframe['num_stopwords'] = dataframe['sentence'].apply(lambda x: np.sum([1 for word in x.split(' ') if word in stop_words])) #calculate number of stopwords\n",
        "    dataframe['ratio_of_stopwords'] = dataframe['num_words'] / dataframe['num_stopwords'] #calculate share of stop words\n",
        "    \n",
        "    # Iterate over each row in the dataframe\n",
        "    for index, row in df.iterrows():\n",
        "        # Part-Of-Speech\n",
        "        counter_pos = POS_count(row['sentence'])\n",
        "        for i in counter_pos:\n",
        "            dataframe.loc[index, i] = counter_pos[i]\n",
        "        \n",
        "        # Entity \n",
        "        counter_ner = entity_count(row['sentence'])\n",
        "        for id in counter_ner:\n",
        "            dataframe.loc[index, i] = counter_ner[i]\n",
        "            \n",
        "    return dataframe.fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "dvsDmFmHMU_A"
      },
      "outputs": [],
      "source": [
        "#remove stop words and punctuation:\n",
        "\n",
        "# Define tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = nlp(sentence)\n",
        "\n",
        "    # Convert each token into lowercase\n",
        "    mytokens = [ word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "DWYUTXEW1sb7"
      },
      "outputs": [],
      "source": [
        "df_aug = data_augmentation(df) #add data augmentation to full data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8Ja1XkiJee5",
        "outputId": "ace3cc6d-1153-4f8a-9548-438d29d3974d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# tokenizer \n",
        "count = CountVectorizer(ngram_range=(1,2), tokenizer=spacy_tokenizer) \n",
        "df_bow = count.fit_transform(df_aug.sentence)\n",
        "\n",
        "# create the bow dataframe\n",
        "df_bow = pd.DataFrame(df_bow.todense(), columns = count.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "sK_DscatJfVH"
      },
      "outputs": [],
      "source": [
        "#split bow dataframe like train and test sets from before:\n",
        "X_train_df = pd.DataFrame(X_train, columns = ['sentence']) #convert to df to merge with full augmented and vectorized dataset\n",
        "X_test_df = pd.DataFrame(X_test, columns = ['sentence'])\n",
        "\n",
        "X_train_bow = X_train_df.join(df_bow).drop(['sentence'], axis=1) #join and drop sentence\n",
        "X_test_bow = X_test_df.join(df_bow).drop(['sentence'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDTimmTyMbzO",
        "outputId": "6d8302eb-b696-42a6-fd1a-7a1d6d210973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[107  39  13   1   1   0]\n",
            " [ 78  63  20   1   1   1]\n",
            " [ 59  38  50   7   1   5]\n",
            " [ 41  21  24  47   5   6]\n",
            " [ 52  22  21  27  31  20]\n",
            " [ 41  17  17  12  17  54]]\n",
            "ACCURACY SCORE:\n",
            "0.3667\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4361\n",
            "\tRecall: 0.3667\n",
            "\tF1_Score: 0.3610\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4360684922903896,\n",
              " 0.36666666666666664,\n",
              " 0.3609991276306834,\n",
              " 0.36666666666666664)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "#Logistic regression:\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_bow, y_train)\n",
        "\n",
        "#prediction:\n",
        "y_pred = log_reg.predict(X_test_bow)\n",
        "\n",
        "# Evaluation - test set:\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf = DecisionTreeClassifier(random_state=0)\n",
        "log_clf = LogisticRegression(random_state=0)\n",
        "knn_clf = KNeighborsClassifier()\n",
        "forest_clf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Training, predicting, then evaluating the predictions\n",
        "# of all three models\n",
        "\n",
        "for clf in (tree_clf, log_clf, knn_clf, forest_clf):\n",
        "    clf.fit(X_train_bow, y_train) # training\n",
        "    y_pred = clf.predict(X_test_bow) # predicting\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred)) # evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drxIdwMUJUg9",
        "outputId": "af447e44-a533-4c30-c9ea-c2d4d7a34297"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier 0.334375\n",
            "LogisticRegression 0.36666666666666664\n",
            "KNeighborsClassifier 0.17291666666666666\n",
            "RandomForestClassifier 0.2989583333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the four models into an ensemble\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# The ensemble is a voting classifier that aggregates our three models\n",
        "voting_clf = VotingClassifier(estimators=[('tree', tree_clf), ('log', log_clf), ('knn', knn_clf), ('forest', forest_clf)], \n",
        "                             voting='hard')\n",
        "\n",
        "voting_clf.fit(X_train_bow, y_train) # training\n",
        "y_pred_voting = voting_clf.predict(X_test_bow) # predicting\n",
        "accuracy_score(y_test, y_pred_voting) \n",
        "evaluate(y_test, y_pred_voting) # evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1hoevq-JY9Z",
        "outputId": "60e83133-d73b-4ed6-966a-0fb3ceb94d2e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[136  19   6   0   0   0]\n",
            " [119  36   8   0   0   1]\n",
            " [108  21  27   2   0   2]\n",
            " [ 82  12  12  25   5   8]\n",
            " [ 83  12  17  18  21  22]\n",
            " [ 79  10  10   6  10  43]]\n",
            "ACCURACY SCORE:\n",
            "0.3000\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4215\n",
            "\tRecall: 0.3000\n",
            "\tF1_Score: 0.2770\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4215050559580921, 0.3, 0.27695075736976005, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and save results for table\n",
        "ensemble_results = evaluate(y_test, y_pred_voting)\n",
        "ensemble_percision = ensemble_results[0]\n",
        "ensemble_recall = ensemble_results[1]\n",
        "ensemble_f1 = ensemble_results[2]\n",
        "ensemble_accuracy = ensemble_results[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9JDdI-6U1WC",
        "outputId": "edff4ad6-7ed3-45d2-892a-4e752a1d4103"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[136  19   6   0   0   0]\n",
            " [119  36   8   0   0   1]\n",
            " [108  21  27   2   0   2]\n",
            " [ 82  12  12  25   5   8]\n",
            " [ 83  12  17  18  21  22]\n",
            " [ 79  10  10   6  10  43]]\n",
            "ACCURACY SCORE:\n",
            "0.3000\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4215\n",
            "\tRecall: 0.3000\n",
            "\tF1_Score: 0.2770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-trained CamemBERT Model"
      ],
      "metadata": {
        "id": "w3jLEvbnWP2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "xZXsXtSs40f2",
        "outputId": "21f367a3-a987-42fd-ee7f-856582e33b13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence difficulty  LE_label\n",
              "0   0  Les co√ªts kilom√©triques r√©els peuvent diverger...         C1         4\n",
              "1   1  Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...         A1         0\n",
              "2   2  Le test de niveau en fran√ßais est sur le site ...         A1         0\n",
              "3   3           Est-ce que ton mari est aussi de Boston?         A1         0\n",
              "4   4  Dans les √©coles de commerce, dans les couloirs...         B1         2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50592fa2-c017-49df-bf05-43b9d438e2fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>LE_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les co√ªts kilom√©triques r√©els peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en fran√ßais est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les √©coles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50592fa2-c017-49df-bf05-43b9d438e2fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50592fa2-c017-49df-bf05-43b9d438e2fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50592fa2-c017-49df-bf05-43b9d438e2fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Use pre-trained CamemBERT model\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE = LabelEncoder()\n",
        "df['LE_label'] = LE.fit_transform(df['difficulty'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['sentence'] \n",
        "y = df['LE_label'] \n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "P8znycFMRH2k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZwWF2_5x4_zF"
      },
      "outputs": [],
      "source": [
        "X_train_list = X_train.values.tolist()\n",
        "X_test_list = X_test.values.tolist()\n",
        "y_train_list = y_train.values.tolist()\n",
        "y_test_list = y_test.values.tolist()\n",
        "\n",
        "X_full = df['sentence'].tolist() #this was our best model, so we will train on the entire dataset\n",
        "y_full = df['LE_label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VqQJL1a25OGF"
      },
      "outputs": [],
      "source": [
        "# Initialize CamemBERT tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\",do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JdrLvj2R5PcA"
      },
      "outputs": [],
      "source": [
        "def preprocess(raw_texts, labels=None):\n",
        "    \"\"\"\n",
        "    Input: list of texts\n",
        "    Returns: pytorch dataloader (format needed for CamemBERT model) including input_ids, attention_masks, and labels (if training)\n",
        "\n",
        "    \"\"\"\n",
        "    encoded_batch = tokenizer.batch_encode_plus(raw_texts,\n",
        "                                                add_special_tokens=True,\n",
        "                                                padding='longest', #pad sentences to match longest sentence (dataset must have rows with same length to input in CamemBERT model)\n",
        "                                                return_attention_mask=True,\n",
        "                                                return_tensors = 'pt') #need pytorch tensors for inputs into CamemBERT model\n",
        "    if labels: #if training will input and return difficulty labels, if using on unseen data there will be no label inputs\n",
        "        labels = torch.tensor(labels)\n",
        "        return encoded_batch['input_ids'], encoded_batch['attention_mask'], labels\n",
        "    return encoded_batch['input_ids'], encoded_batch['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "102dv9JU5UVJ"
      },
      "outputs": [],
      "source": [
        "#Combine input ids, labels, and attention masks for:\n",
        "\n",
        "#training set\n",
        "input_ids, attention_mask, labels_train = preprocess(X_train_list, y_train_list)\n",
        "train_dataset = TensorDataset(input_ids, attention_mask, labels_train)\n",
        "\n",
        "#full dataset (this is the final model and so we trained it on the full dataset)\n",
        "input_ids, attention_mask, labels_test = preprocess(X_full, y_full)\n",
        "full_dataset = TensorDataset(input_ids, attention_mask, labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Nxki-7Ke5UE6"
      },
      "outputs": [],
      "source": [
        "batch_size = 4 #4, 8, 16, 32 (used 32 for kaggle submission)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size)\n",
        "full_dataloader = DataLoader(full_dataset, sampler = SequentialSampler(full_dataset), batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSj4F3H55Tzq",
        "outputId": "62e47fc8-0134-4066-c866-7d5b238fdb8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pretrained camemBERT model \n",
        "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mcdrcxPA8PMv"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WRk_xZBL80H-"
      },
      "outputs": [],
      "source": [
        "import gc \n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Rb65A55j5TjT"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqZ065iM8IEq",
        "outputId": "b38b47e7-d64b-4742-dab8-e3197e35dc21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "########## Epoch 0 / 10 ##########\n",
            "Train loss: 1.3139491327727835\n",
            "\n",
            "########## Epoch 1 / 10 ##########\n",
            "Train loss: 0.9698459891757617\n",
            "\n",
            "########## Epoch 2 / 10 ##########\n",
            "Train loss: 0.723643769378153\n",
            "\n",
            "########## Epoch 3 / 10 ##########\n",
            "Train loss: 0.5597505398948367\n",
            "\n",
            "########## Epoch 4 / 10 ##########\n",
            "Train loss: 0.4430055876408005\n",
            "\n",
            "########## Epoch 5 / 10 ##########\n",
            "Train loss: 0.3514152300924858\n",
            "\n",
            "########## Epoch 6 / 10 ##########\n",
            "Train loss: 0.28636445532053284\n",
            "\n",
            "########## Epoch 7 / 10 ##########\n",
            "Train loss: 0.2299204265839459\n",
            "\n",
            "########## Epoch 8 / 10 ##########\n",
            "Train loss: 0.18814127410842046\n",
            "\n",
            "########## Epoch 9 / 10 ##########\n",
            "Train loss: 0.1963006818931414\n",
            "Model saved!\n"
          ]
        }
      ],
      "source": [
        "#Train on full dataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "torch.cuda.set_device(0)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "epochs = 10 #(set to 50 for kaggle submission)\n",
        "\n",
        "# Training\n",
        "for epoch in range(0, epochs):\n",
        "    \n",
        "    print(\"\")\n",
        "    print(f'########## Epoch {epoch} / {epochs} ##########')\n",
        "\n",
        "    # Tracking variables for training\n",
        "    train_loss = 0\n",
        "    num_train_examples, num_train_steps = 0, 0\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "    # For each batch of training data\n",
        "    for step, batch in enumerate(train_dataloader): #full_dataloader (when training on full dataset for kaggle submission)\n",
        "\n",
        "        input_id = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        # Clear old gradients before backward pass\n",
        "        model.zero_grad()        \n",
        "        # Forward pass\n",
        "        outputs = model(input_id,token_type_ids=None, attention_mask=attention_mask, labels=labels)\n",
        "        # Get loss value\n",
        "        loss = outputs[0]\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Clip the norm of the gradients to 1.0 to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # Update parameters and take a step \n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        train_loss += loss.item()\n",
        "        num_train_examples += input_id.size(0)\n",
        "        num_train_steps += 1\n",
        "\n",
        "    print(\"Train loss: {}\".format(train_loss/num_train_steps))\n",
        "    torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/DMML_project/camembert_model.pt\")\n",
        "    \n",
        " \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Model saved!\")\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/DMML_project/camembert_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing set\n",
        "input_ids_test, attention_mask_test, labels_test_test = preprocess(X_test_list, y_test_list)"
      ],
      "metadata": {
        "id": "2IJpmShtbrgj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the finetuned model (Camembert)\n",
        "device = torch.device('cpu') \n",
        "model.to(device)\n",
        "\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    outputs =  model(input_ids_test,token_type_ids=None, attention_mask=attention_mask_test)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy() \n",
        "    y_pred.extend(np.argmax(logits, axis=1).flatten())"
      ],
      "metadata": {
        "id": "b9hmla_bbb57"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_test_list, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2g7dR7XcGX6",
        "outputId": "60a0e67c-43a3-4ae6-905e-8757d74e628a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[117  35   8   0   1   0]\n",
            " [ 39  90  28   7   0   0]\n",
            " [  9  43  91  15   2   0]\n",
            " [  0   1  16  88  31   8]\n",
            " [  0   2   5  54  81  31]\n",
            " [  0   0   4  11  39 104]]\n",
            "ACCURACY SCORE:\n",
            "0.5948\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.5985\n",
            "\tRecall: 0.5948\n",
            "\tF1_Score: 0.5952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and save results for table\n",
        "cb_results = evaluate(y_test_list, y_pred)\n",
        "cb_percision = cb_results[0]\n",
        "cb_recall = cb_results[1]\n",
        "cb_f1 = cb_results[2]\n",
        "cb_accuracy = cb_results[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zuFKjnmS8__",
        "outputId": "4b220461-273e-44ff-c0b5-30c0a91008e2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[117  35   8   0   1   0]\n",
            " [ 39  90  28   7   0   0]\n",
            " [  9  43  91  15   2   0]\n",
            " [  0   1  16  88  31   8]\n",
            " [  0   2   5  54  81  31]\n",
            " [  0   0   4  11  39 104]]\n",
            "ACCURACY SCORE:\n",
            "0.5948\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.5985\n",
            "\tRecall: 0.5948\n",
            "\tF1_Score: 0.5952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kaggle Submission"
      ],
      "metadata": {
        "id": "9bDeNtqGeBHI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FuNLaefh8H4C"
      },
      "outputs": [],
      "source": [
        "#Before running make sure to train model on FULL dataset. This is the final output for submission to kaggle:\n",
        "#test on unseen data:\n",
        "sentences = df_pred['sentence'].to_list()\n",
        "\n",
        "#tokenize:\n",
        "tokenized_sentences_ids = [tokenizer.encode(sentence,add_special_tokens=True,padding='longest') for sentence in sentences]\n",
        "# Pad the encoded sentences:\n",
        "tokenized_sentences_ids = pad_sequences(tokenized_sentences_ids, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks:\n",
        "attention_masks = []\n",
        "for seq in tokenized_sentences_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "#create pytorch inputs for model:\n",
        "prediction_inputs = torch.tensor(tokenized_sentences_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "z1662X228Hqa"
      },
      "outputs": [],
      "source": [
        "# Apply the finetuned model (Camembert)\n",
        "flat_pred = []\n",
        "with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    outputs =  model(prediction_inputs.to(device),token_type_ids=None, attention_mask=prediction_masks.to(device))\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy() \n",
        "    flat_pred.extend(np.argmax(logits, axis=1).flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ONYcYUHV8HYV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bd8a4cf8-ea17-4c16-ba66-bc5220028c4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id difficulty\n",
              "0        0         C2\n",
              "1        1         A2\n",
              "2        2         B1\n",
              "3        3         A2\n",
              "4        4         C2\n",
              "...    ...        ...\n",
              "1195  1195         B1\n",
              "1196  1196         A2\n",
              "1197  1197         C2\n",
              "1198  1198         B2\n",
              "1199  1199         B2\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f0738b9-b960-4ff9-9680-7b46f49a0af2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1195</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1196</td>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1197</td>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1198</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1199</td>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f0738b9-b960-4ff9-9680-7b46f49a0af2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f0738b9-b960-4ff9-9680-7b46f49a0af2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f0738b9-b960-4ff9-9680-7b46f49a0af2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#convert results to a dataframe\n",
        "d = {'sentence':sentences,'difficulty_label':flat_pred}\n",
        "df_test = pd.DataFrame(d)\n",
        "\n",
        "#relabel difficulty:\n",
        "difficulty = {\n",
        "    0:\"A1\",\n",
        "    1:\"A2\",\n",
        "    2:\"B1\",\n",
        "    3:\"B2\", \n",
        "    4:\"C1\", \n",
        "    5:\"C2\"\n",
        "}\n",
        "#map categorical value back to difficulty rating:\n",
        "df_test[\"difficulty\"] = df_test['difficulty_label'].map(difficulty)\n",
        "df_test.reset_index(inplace=True)\n",
        "df_test = df_test.rename(columns = {'index':'id'})\n",
        "\n",
        "df_pred_results = df_test[[ \"id\",\"difficulty\"]]\n",
        "df_pred_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cE1fvA25TKD"
      },
      "outputs": [],
      "source": [
        "df_pred_results.to_csv('/content/drive/MyDrive/Colab Notebooks/DMML_project/microsoft_submission11.csv', index=False) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82FvnJycsBFf"
      },
      "source": [
        "#### 4.7. Show a summary of your results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaUIgMDgXJ0c",
        "outputId": "ac017954-2bbb-4a95-c194-42d9f1679d87"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (0.8.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "dQyoXAzkXKNv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = [[\"Precision\", log_reg_percision, knn_percision, tree_percision, forest_percision, ensemble_percision, cb_percision],\n",
        "              [\"Recall\", log_reg_recall, knn_recall, tree_recall, forest_recall, ensemble_recall, cb_recall],\n",
        "              [\"F1-Score\", log_reg_f1, knn_f1, tree_f1, forest_f1, ensemble_f1, cb_f1],\n",
        "              [\"Accuracy\", log_reg_accuracy, knn_accuracy, tree_accuracy, forest_accuracy, ensemble_accuracy, cb_accuracy]]\n",
        "\n",
        "col_names = [\"Logistic Regression\", \"KNN\", \"Decision Tree\", \"Random Forest\", \"Ensemble + Data Augmentation\", \"CamemBERT\"]\n",
        "print(tabulate(results_df, headers=col_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmisQ_WoPYXq",
        "outputId": "c6078799-5d76-4092-91e2-a4b23b343e61"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Logistic Regression       KNN    Decision Tree    Random Forest    Ensemble + Data Augmentation    CamemBERT\n",
            "---------  ---------------------  --------  ---------------  ---------------  ------------------------------  -----------\n",
            "Precision               0.486521  0.403741         0.346448         0.388571                        0.421505     0.598524\n",
            "Recall                  0.485417  0.398958         0.339583         0.396875                        0.3          0.594792\n",
            "F1-Score                0.482333  0.376673         0.330539         0.372308                        0.276951     0.595161\n",
            "Accuracy                0.485417  0.398958         0.339583         0.396875                        0.3          0.594792\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}